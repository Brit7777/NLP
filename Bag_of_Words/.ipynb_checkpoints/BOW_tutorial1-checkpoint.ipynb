{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "header = 0 은 파일의 첫번째 줄에 열이름 있음을 나타내고\n",
    "delimiter = \\t 은 필드가 탭으로 구분됨\n",
    "quoting = 3은 쌍따옴표 무시\n",
    "'''\n",
    "# train data with label(sentiment)\n",
    "train = pd.read_csv('./data/word2vec-nlp-tutorial/labeledTrainData.tsv', header=0, delimiter='\\t', quoting=3)\n",
    "#test data w/o label\n",
    "test = pd.read_csv('./data/word2vec-nlp-tutorial/testData.tsv', header=0, delimiter='\\t', quoting=3)\n",
    "\n",
    "#25000 rows and 3 columns\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#25000 rows and 2 columns(sentiment excluded)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>\"Naturally in a film who's main themes are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>\"This movie is a disaster within a disaster fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>\"All in all, this is a movie for kids. We saw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>\"Afraid of the Dark left me with the impressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>\"A very accurate depiction of small time mob l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                             review\n",
       "0  \"12311_10\"  \"Naturally in a film who's main themes are of ...\n",
       "1    \"8348_2\"  \"This movie is a disaster within a disaster fi...\n",
       "2    \"5828_4\"  \"All in all, this is a movie for kids. We saw ...\n",
       "3    \"7186_2\"  \"Afraid of the Dark left me with the impressio...\n",
       "4   \"12128_7\"  \"A very accurate depiction of small time mob l..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'sentiment', 'review'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'review'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only 700 characters\n",
    "#since html tag is included, 정제 needed\n",
    "train['review'][0][:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Text Preprocessing\n",
    "\n",
    "In order to prevent overfitting from outliers(abnormal data), **data cleaning** is required.\n",
    "\n",
    "1. HTML tag removal with BeautifulSoup\n",
    "2. replacing characters that is not alphabet with space using regular expression(정규표현식 사용)\n",
    "3. Stopword(불용어) removal with NLTK\n",
    "> e.g.) I, my, me와 같이 자주 등장하지만 의미가 많지 않은 데이터\n",
    "4. 어간추출 with SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*만약 한국어로 전처리를 하고싶다면?*\n",
    "[KoNLPy](https://github.com/twitter/twitter-korean-text) 사용!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HTML Tag Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely lik\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#전처리전\n",
    "print(train['review'][0][:700])\n",
    "#전처리후\n",
    "example1 = BeautifulSoup(train['review'][0],'html5lib')\n",
    "example1.get_text()[:700]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Replacing non-alphabetical characters with blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' With all this stuff going down at the moment with MJ i ve started listening to his music  watching the odd documentary here and there  watched The Wiz and watched Moonwalker again  Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent  Moonwalker is part biography  part feature film which i remember going to see at the cinema when it was originally released  Some of it has subtle messages about MJ s feeling towards the press and also the obvious message of drugs are bad m kay Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyw'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for regular expression\n",
    "import re\n",
    "\n",
    "#^ = not\n",
    "letters_only = re.sub('[^a-zA-Z]',' ', example1.get_text())\n",
    "letters_only[:700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'going',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'with']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change to lowercase\n",
    "lower_case = letters_only.lower()\n",
    "#split sentences to words = 토큰화\n",
    "words = lower_case.split()\n",
    "print(len(words))\n",
    "words[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stopword Removal\n",
    "\n",
    "Stopword(e.g. i, me, it, this that, is, are, to, the) does not contribute to the actual meaning of sentence. \n",
    "\n",
    "Therefore, let's use [NLTK](https://www.nltk.org) since it contains 153 stopwords in 17 languages including English.\n",
    "\n",
    "*단, 한국어는 아직 없다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/brit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stopwords from tokens\n",
    "words = [w for w in words if not w in stopwords.words('english')]\n",
    "print(len(words))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stemming(어간추출, 형태소 분석)\n",
    "[어간추출](https://ko.wikipedia.org/wiki/어간_추출)\n",
    "> i.e. message, messages, messaging can be classified as simply 'message'\n",
    "\n",
    "**NLTK** also provides this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum\n",
      "The stemmed form of runs is: run\n",
      "The stemmed form of runs is: run\n",
      "The stemmed form of run is: run\n"
     ]
    }
   ],
   "source": [
    "#stemmer example\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "print(stemmer.stem('maximum'))\n",
    "print(\"The stemmed form of runs is: {}\".format(stemmer.stem(\"running\")))\n",
    "print(\"The stemmed form of runs is: {}\".format(stemmer.stem(\"runs\")))\n",
    "print(\"The stemmed form of run is: {}\".format(stemmer.stem(\"run\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'go',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'start',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'watch',\n",
       " 'odd',\n",
       " 'documentari']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "words = [stemmer.stem(w) for w in words]\n",
    "#result\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization 음소표기법\n",
    "한국어로 예를 들자면, \n",
    "1) 배가 맛있다\n",
    "2) 배를 타는 것은 재밌다.\n",
    "3) 음식을 잘못먹어서 배가 아프다\n",
    "\n",
    " 여기서 '배'는 3개의 다른 의미를 가진 단어로 **앞뒤 문맥을 보고 의미를 식별**할 필요가 있다.\n",
    " \n",
    " Examples in English:\n",
    " 1) John is right in front of me because I can see him.\n",
    " 2) John and I used to go out, but he is seeing someone else now. \n",
    " \n",
    " A word 'see' may contain different meanings in diffent context. Hence, **examining words in context** is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/brit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "fly\n"
     ]
    }
   ],
   "source": [
    "#lemmatizer example\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(wordnet_lemmatizer.lemmatize('fly'))\n",
    "print(wordnet_lemmatizer.lemmatize('flies'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [wordnet_lemmatizer.lemmatize(w) for w in words]\n",
    "# result\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's put it into action now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words( raw_review ):\n",
    "    # 1. HTML removal\n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "    # 2. non-alphabetical characters -> blank\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', review_text)\n",
    "    # 3. every letter to lowercase \n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # 4. Stopwords removal\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 5. stemming\n",
    "    stemming_words = [stemmer.stem(w) for w in meaningful_words]\n",
    "    return( ' '.join(stemming_words) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stuff go moment mj start listen music watch odd documentari watch wiz watch moonwalk mayb want get certain insight guy thought realli cool eighti mayb make mind whether guilti innoc moonwalk part biographi part featur film rememb go see cinema origin releas subtl messag mj feel toward press also obviou messag drug bad kay visual impress cours michael jackson unless remot like mj anyway go hate find bore may call mj egotist consent make movi mj fan would say made fan true realli nice actual featur film bit final start minut exclud smooth crimin sequenc joe pesci convinc psychopath power drug lord want mj dead bad beyond mj overheard plan nah joe pesci charact rant want peopl know suppli drug etc dunno mayb hate mj music lot cool thing like mj turn car robot whole speed demon sequenc also director must patienc saint came film kiddi bad sequenc usual director hate work one kid let alon whole bunch perform complex danc scene bottom line movi peopl like mj one level anoth think peopl stay away tri give wholesom messag iron mj bestest buddi movi girl michael jackson truli one talent peopl ever grace planet guilti well attent gave subject hmmm well know peopl differ behind close door know fact either extrem nice stupid guy one sickest liar hope latter'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_review = review_to_words(train['review'][0])\n",
    "clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of review data\n",
    "num_review = train['review'].size\n",
    "num_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고 : https://gist.github.com/yong27/7869662\n",
    "# http://www.racketracer.com/2016/07/06/pandas-in-parallel/\n",
    "\n",
    "#since it takes way too long to preprocess 25000 data, we use multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "\n",
    "def _apply_df(args):\n",
    "    df, func, kwargs = args\n",
    "    return df.apply(func, **kwargs)\n",
    "\n",
    "def apply_by_multiprocessing(df, func, **kwargs):\n",
    "    # 키워드 항목 중 workers 파라메터를 꺼냄\n",
    "    workers = kwargs.pop('workers')\n",
    "    # 위에서 가져온 workers 수로 프로세스 풀을 정의\n",
    "    pool = Pool(processes=workers)\n",
    "    # 실행할 함수와 데이터프레임을 워커의 수 만큼 나눠 작업\n",
    "    result = pool.map(_apply_df, [(d, func, kwargs)\n",
    "            for d in np.array_split(df, workers)])\n",
    "    pool.close()\n",
    "    # 작업 결과를 합쳐서 반환\n",
    "    return pd.concat(list(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 103 ms, sys: 106 ms, total: 209 ms\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%time clean_train_reviews = apply_by_multiprocessing(train['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.3 ms, sys: 111 ms, total: 210 ms\n",
      "Wall time: 31.3 s\n"
     ]
    }
   ],
   "source": [
    "%time clean_test_reviews = apply_by_multiprocessing(test['review'], review_to_words, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=20000, min_df=2,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', tokenizer=None, preprocessor=None,\n",
    "                            stop_words=None, min_df=2, #토큰이 나타날 최소 문서 개수\n",
    "                            ngram_range=(1,3), max_features=20000)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 s, sys: 802 ms, total: 26.4 s\n",
      "Wall time: 26.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<25000x20000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2757913 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to improve speed\n",
    "pipeline = Pipeline([('vect', vectorizer)])\n",
    "\n",
    "%time train_data_features = pipeline.fit_transform(clean_train_reviews)\n",
    "train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape\n",
    "#number of features = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['aag',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abbey',\n",
       " 'abbi',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abc',\n",
       " 'abduct']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "#number of vocab = number of features\n",
    "print(len(vocab))\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aag</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abc</th>\n",
       "      <th>abduct</th>\n",
       "      <th>...</th>\n",
       "      <th>zombi bloodbath</th>\n",
       "      <th>zombi film</th>\n",
       "      <th>zombi flick</th>\n",
       "      <th>zombi movi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zu</th>\n",
       "      <th>zucker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>288</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>89</td>\n",
       "      <td>161</td>\n",
       "      <td>31</td>\n",
       "      <td>71</td>\n",
       "      <td>59</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 20000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aag  aaron  ab  abandon  abbey  abbi  abbot  abbott  abc  abduct   ...    \\\n",
       "0   26     48  22      288     24    30     29      30  125      55   ...     \n",
       "\n",
       "   zombi bloodbath  zombi film  zombi flick  zombi movi  zone  zoo  zoom  \\\n",
       "0               23          52           37          89   161   31    71   \n",
       "\n",
       "   zorro  zu  zucker  \n",
       "0     59  40      23  \n",
       "\n",
       "[1 rows x 20000 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "pd.DataFrame(dist,columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Prediction using Random Forest\n",
    "  여러개의 decision tree(T/F로 계속 파고드는 트리형태)를 만들어 평균값/투표 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "            oob_score=False, random_state=2018, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#n_estimators = number of cpu cores to use(-1 means use everything)\n",
    "forest = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=2018)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 246 ms, total: 1min 3s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "# X_train : 행렬 / Y_train : 벡터\n",
    "%time forest = forest.fit(train_data_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.49 s, sys: 2.11 s, total: 9.6 s\n",
      "Wall time: 2min 39s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "%time score = np.mean(cross_val_score(forest, train_data_features, \\\n",
    "                                     train['sentiment'], cv=10, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.67 s, sys: 347 ms, total: 7.02 s\n",
      "Wall time: 7.34 s\n"
     ]
    }
   ],
   "source": [
    "# vectorizing test data\n",
    "%time test_data_features = pipeline.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "result = forest.predict(test_data_features)\n",
    "result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          1\n",
       "3    \"7186_2\"          1\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save result to dataframe\n",
    "output = pd.DataFrame(data={\"id\":test[\"id\"],\"sentiment\":result})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12551\n",
       "0    12449\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentiment=output['sentiment'].value_counts()\n",
    "#positive vs negative\n",
    "print(output_sentiment[0] - output_sentiment[1])\n",
    "output_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('tutorial_1_BOW_{0:5f}.csv'.format(score), index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
