{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is attention mechanism?\n",
    "Each time the model predicts an output word, it only **uses parts of an input where the most relevant information is concentrated** instead of an entire sentence.\n",
    "\n",
    "## How do we use it?\n",
    "<img width=\"647\" alt=\"image\" src=\"https://user-images.githubusercontent.com/35142536/62429376-11405580-b6dc-11e9-8cfa-ae62ac45003b.png\">\n",
    "As you can see in the picture, encoder works as usual, but the decoder’s hidden state is computed with a context vector, the previous output and the previous hidden state. These context vectors are computed as a weighted sum of annotations generated by the encoder.\n",
    "\n",
    "## Why do we need Attention mechanism?\n",
    "Seq2Seq model is an “encoder-decoder”. There, one part of the network — encoder — encodes the input sequence into a **fixed-length context vector** and this context vector is then decoded into the output sequence by the decoder. ->  leads to a **decline in performance** when dealing with **long sentences**\n",
    "\n",
    "> https://medium.com/@joealato/attention-in-nlp-734c6fa9d983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Code (German -> English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': 0, 'ich': 1, 'mochte': 2, 'i': 3, 'want': 4, 'a': 5, 'bier': 6, 'E': 7, 'beer': 8, 'P': 9, 'ein': 10}\n"
     ]
    }
   ],
   "source": [
    "# S: Symbol that shows starting of decoding input\n",
    "# E: Symbol that shows starting of decoding output\n",
    "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
    "sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
    "\n",
    "# combine all the words with \" \" on the back\n",
    "word_list = \" \".join(sentences).split()\n",
    "word_list = list(set(word_list))\n",
    "word_dict = {w:i for i, w in enumerate(word_list)}\n",
    "number_dict = {i:w for i,w in enumerate(word_list)}\n",
    "n_class = len(word_dict)\n",
    "\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "n_step = 5 # maxium number of words in one sentence(=number of time steps)\n",
    "n_hidden = 128\n",
    "\n",
    "def make_batch(sentences):\n",
    "    #one-hot encoding for input and output\n",
    "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
    "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
    "    target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "enc_inputs = tf.placeholder(tf.float32, [None, None, n_class]) # [batch_size, n_step, n_class]\n",
    "dec_inputs = tf.placeholder(tf.float32, [None, None, n_class])\n",
    "targets = tf.placeholder(tf.int64, [1, n_step]) # [batch_size, n_step] , one-hot X\n",
    "\n",
    "# linear for attention\n",
    "attn = tf.Variable(tf.random_normal([n_hidden, n_hidden]))\n",
    "out = tf.Variable(tf.random_normal([n_hidden*2, n_class]))\n",
    "\n",
    "def get_attn_score(dec_output, enc_output):\n",
    "    score = tf.squeeze(tf.matmul(enc_output, attn), 0)\n",
    "    dec_output = tf.squeeze(dec_output, [0,1]) \n",
    "    return tf.tensordot(dec_output, score, 1)\n",
    "\n",
    "def get_attn_weight(dec_output, enc_outputs):\n",
    "    attn_scores = []\n",
    "    enc_outputs = tf.transpose(enc_outputs, [1,0,2])\n",
    "    for i in range(n_step):\n",
    "        attn_scores.append(get_attn_score(dec_output, enc_outputs[i]))\n",
    "\n",
    "    # Normalize scores to weights in range 0 to 1\n",
    "    return tf.reshape(tf.nn.softmax(attn_scores), [1, 1, -1])  # [1, 1, n_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-1839dd27edcb>:6: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-1839dd27edcb>:10: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "Attention = []\n",
    "\n",
    "# encode is the same as the original Seq2Seq model\n",
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n",
    "    # enc_outputs : [batch_size(=1), n_step(=decoder_step), n_hidden(=128)]\n",
    "    # enc_hidden : [batch_size(=1), n_hidden(=128)]\n",
    "    enc_outputs, enc_hidden = tf.nn.dynamic_rnn(enc_cell, enc_inputs, dtype=tf.float32)\n",
    "\n",
    "\n",
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    inputs = tf.transpose(dec_inputs, [1,0,2])\n",
    "    hidden = enc_hidden\n",
    "    \n",
    "    for i in range(n_step):\n",
    "         # time_major True mean inputs shape: [max_time, batch_size, ...]\n",
    "        dec_output, hidden = tf.nn.dynamic_rnn(dec_cell, tf.expand_dims(inputs[i], 1),\n",
    "                                               initial_state=hidden, dtype=tf.float32, time_major=True)\n",
    "        attn_weights = get_attn_weight(dec_output, enc_outputs) # [1,1,n_step]\n",
    "        Attention.append(tf.squeeze(attn_weights))\n",
    "         # matrix-matrix product of matrices [1, 1, n_step] x [1, n_step, n_hidden] = [1, 1, n_hidden]\n",
    "        context = tf.matmul(attn_weights, enc_outputs)\n",
    "        dec_output = tf.squeeze(dec_output, 0)  # [1, n_step]\n",
    "        context = tf.squeeze(context, 1)  # [1, n_hidden]\n",
    "\n",
    "        model.append(tf.matmul(tf.concat((dec_output, context), 1), out))  # [n_step, batch_size(=1), n_class]\n",
    "        \n",
    "trained_attn = tf.stack([Attention[0], Attention[1], Attention[2], Attention[3], Attention[4]],0)\n",
    "# to show attention matrix\n",
    "model = tf.transpose(model, [1,0,2]) #model : [n_step, n_class]\n",
    "prediction = tf.argmax(model,2)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=targets))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0400 cost = 0.000000\n",
      "Epoch: 0800 cost = 0.000004\n",
      "Epoch: 1200 cost = 0.000000\n",
      "Epoch: 1600 cost = 0.000000\n",
      "Epoch: 2000 cost = 0.000000\n",
      "['ich', 'mochte', 'ein', 'bier', 'P'] -> ['i', 'want', 'a', 'beer', 'E']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and test\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    for epoch in range(2000):\n",
    "        input_batch, output_batch, target_batch = make_batch(sentences)\n",
    "        _, loss, attention = sess.run([optimizer, cost, trained_attn], feed_dict={enc_inputs: input_batch, dec_inputs: output_batch, targets: target_batch})\n",
    "        if (epoch + 1) % 400 == 0:\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
    "            \n",
    "       \n",
    "    predict_batch = [np.eye(n_class)[[word_dict[n] for n in 'P P P P P'.split()]]]\n",
    "    result = sess.run(prediction, feed_dict={enc_inputs: input_batch, dec_inputs: predict_batch})\n",
    "    print(sentences[0].split(), '->', [number_dict[n] for n in result[0]])\n",
    "        \n",
    "    # show attention\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
    "    ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
